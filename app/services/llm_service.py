from typing import List, Dict

# Replace these with your Python LLM / embedding library
def generate_embedding(text: str) -> List[float]:
    # TODO: implement using OpenAI, Hugging Face, or any Python library
    return [0.0] * 768  # placeholder

def generate_answer(context: str, question: str) -> str:
    # TODO: implement Python LLM call
    return f"Answer generated by backend LLM using context: {context[:200]}..."
